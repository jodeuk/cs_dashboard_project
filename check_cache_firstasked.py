#!/usr/bin/env python3
import sys
import os

# pandasì™€ pickleì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ê²½ë¡œ ì¶”ê°€
try:
    import pandas as pd
    import pickle
    import json
except ImportError as e:
    print(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    print("pandasê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”: pip install pandas")
    sys.exit(1)

# ë¡œì»¬ ìºì‹œ ë””ë ‰í† ë¦¬
local_cache_dir = "/home/elice/cs_dashboard_project/cache"

# Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ìºì‹œ í™•ì¸
import subprocess

print("ìºì‹œ ë””ë ‰í† ë¦¬ í™•ì¸:\n")
print(f"  ë¡œì»¬: {local_cache_dir}")

# Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
docker_files = []
try:
    result = subprocess.run(
        ["docker", "exec", "cs_dashboard_backend", "ls", "/data/cache/"],
        capture_output=True,
        text=True,
        timeout=5
    )
    if result.returncode == 0:
        docker_files = [f.strip() for f in result.stdout.split('\n') if f.strip().startswith("userchats_") and f.strip().endswith(".pkl")]
        print(f"  Docker ì»¨í…Œì´ë„ˆ: /data/cache (íŒŒì¼ {len(docker_files)}ê°œ ë°œê²¬)")
    else:
        print(f"  Docker ì»¨í…Œì´ë„ˆ: ì ‘ê·¼ ì‹¤íŒ¨ ({result.stderr})")
except Exception as e:
    print(f"  Docker ì»¨í…Œì´ë„ˆ: í™•ì¸ ì‹¤íŒ¨ ({e})")

print()

# ë¡œì»¬ íŒŒì¼ ì°¾ê¸°
local_files = []
if os.path.exists(local_cache_dir):
    try:
        local_files = [f for f in os.listdir(local_cache_dir) if f.startswith("userchats_") and f.endswith(".pkl")]
    except Exception as e:
        print(f"âš ï¸ ë¡œì»¬ ë””ë ‰í† ë¦¬ ì½ê¸° ì‹¤íŒ¨: {e}")

# Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ íŒŒì¼ë„ í™•ì¸ (docker execë¡œ íŒŒì¼ ì½ê¸°)
all_cache_files = []

# ë¡œì»¬ íŒŒì¼ ì¶”ê°€
for f in local_files:
    all_cache_files.append(("ë¡œì»¬", local_cache_dir, f))

# Docker íŒŒì¼ ì¶”ê°€ (ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ì½ê¸°)
for f in docker_files:
    all_cache_files.append(("Docker", "/data/cache", f))

cache_files = all_cache_files

if not cache_files:
    print("userchats ìºì‹œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

print(f"ë°œê²¬ëœ ìºì‹œ íŒŒì¼: {len(cache_files)}ê°œ\n")

for name, cache_dir, cache_file in sorted(cache_files, key=lambda x: x[2]):
    print("=" * 80)
    print(f"ìºì‹œ íŒŒì¼: {cache_file} ({name})")
    print(f"ê²½ë¡œ: {cache_dir}/{cache_file}")
    print("=" * 80)
    
    try:
        # DataFrame ë¡œë“œ
        print("ìºì‹œ íŒŒì¼ ë¡œë“œ ì¤‘...")
        
        # Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ íŒŒì¼ì¸ ê²½ìš° docker execë¡œ ì½ê¸°
        if name == "Docker":
            import tempfile
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as tmp_file:
                tmp_path = tmp_file.name
            try:
                # ì»¨í…Œì´ë„ˆì—ì„œ íŒŒì¼ ë³µì‚¬
                result = subprocess.run(
                    ["docker", "cp", f"cs_dashboard_backend:{cache_dir}/{cache_file}", tmp_path],
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                if result.returncode != 0:
                    print(f"âŒ íŒŒì¼ ë³µì‚¬ ì‹¤íŒ¨: {result.stderr}")
                    continue
                df = pd.read_pickle(tmp_path)
                os.unlink(tmp_path)
            except Exception as e:
                if os.path.exists(tmp_path):
                    os.unlink(tmp_path)
                raise e
        else:
            cache_path = os.path.join(cache_dir, cache_file)
            df = pd.read_pickle(cache_path)
        
        meta_path = None
        if name == "Docker":
            # ë©”íƒ€ë°ì´í„°ë„ ë³µì‚¬í•´ì„œ ì½ê¸°
            import tempfile
            with tempfile.NamedTemporaryFile(delete=False, suffix='.json') as tmp_meta:
                tmp_meta_path = tmp_meta.name
            try:
                meta_file = cache_file.replace(".pkl", "_metadata.json")
                result = subprocess.run(
                    ["docker", "cp", f"cs_dashboard_backend:{cache_dir}/{meta_file}", tmp_meta_path],
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                if result.returncode == 0:
                    meta_path = tmp_meta_path
            except:
                pass
        else:
            cache_path = os.path.join(cache_dir, cache_file)
            meta_path = cache_path.replace(".pkl", "_metadata.json")
        print(f"âœ… ì´ í–‰ ìˆ˜: {len(df)}")
        
        # ì»¬ëŸ¼ í™•ì¸
        if 'firstAskedAt' not in df.columns:
            print("âš ï¸ ê²½ê³ : 'firstAskedAt' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}")
            continue
        
        if 'createdAt' not in df.columns:
            print("âš ï¸ ê²½ê³ : 'createdAt' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            continue
        
        # firstAskedAtì´ NaNì¸ í–‰ í™•ì¸
        first_na = df['firstAskedAt'].isna()
        first_na_count = first_na.sum()
        print(f"\nğŸ“Š firstAskedAtì´ NaNì¸ í–‰: {first_na_count}ê°œ ({first_na_count/len(df)*100:.2f}%)")
        
        # createdAtì€ ìˆì§€ë§Œ firstAskedAtì´ ì—†ëŠ” í–‰
        created_not_na = df['createdAt'].notna()
        both_condition = first_na & created_not_na
        both_count = both_condition.sum()
        print(f"ğŸ“Š createdAtì€ ìˆì§€ë§Œ firstAskedAtì´ ì—†ëŠ” í–‰: {both_count}ê°œ")
        
        if both_count > 0:
            print(f"\nğŸ” [ìƒ˜í”Œ ë°ì´í„° - createdAtì€ ìˆì§€ë§Œ firstAskedAtì´ ì—†ëŠ” í–‰]")
            sample = df[both_condition].head(5)
            for idx, row in sample.iterrows():
                print(f"\n  í–‰ {idx}:")
                print(f"    userId: {row.get('userId', 'N/A')}")
                print(f"    userChatId: {row.get('userChatId', 'N/A')}")
                print(f"    direction: {row.get('direction', 'N/A')}")
                print(f"    mediumType: {row.get('mediumType', 'N/A')}")
                print(f"    firstAskedAt: {row.get('firstAskedAt')}")
                print(f"    createdAt: {row.get('createdAt')}")
                
                # directionì´ OBê°€ ë§ëŠ”ì§€ í™•ì¸
                if row.get('direction') != 'OB':
                    print(f"    âš ï¸ ê²½ê³ : directionì´ OBê°€ ì•„ë‹™ë‹ˆë‹¤! (í˜„ì¬: {row.get('direction')})")
        
        # direction ë¶„í¬ í™•ì¸
        if 'direction' in df.columns:
            print(f"\nğŸ“Š [direction ë¶„í¬ (ì „ì²´)]")
            direction_counts = df['direction'].value_counts()
            for direction, count in direction_counts.items():
                print(f"    {direction}: {count}ê°œ ({count/len(df)*100:.2f}%)")
            
            # phone ë°ì´í„°ì˜ direction ë¶„í¬
            if 'mediumType' in df.columns:
                phone_df = df[df['mediumType'] == 'phone']
                if len(phone_df) > 0:
                    print(f"\nğŸ“Š [phone ë°ì´í„° í†µê³„]")
                    print(f"    ì´ phone ë°ì´í„°: {len(phone_df)}ê°œ")
                    
                    phone_direction = phone_df['direction'].value_counts()
                    print(f"    direction ë¶„í¬:")
                    for direction, count in phone_direction.items():
                        print(f"      {direction}: {count}ê°œ ({count/len(phone_df)*100:.2f}%)")
                    
                    # phone ë°ì´í„° ì¤‘ firstAskedAtì´ ì—†ì§€ë§Œ createdAtì´ ìˆëŠ” ê²½ìš°
                    phone_first_na = phone_df['firstAskedAt'].isna()
                    phone_created_not_na = phone_df['createdAt'].notna()
                    phone_both = phone_first_na & phone_created_not_na
                    phone_both_count = phone_both.sum()
                    print(f"\n    phone ë°ì´í„° ì¤‘ firstAskedAt ì—†ì§€ë§Œ createdAt ìˆëŠ” í–‰: {phone_both_count}ê°œ")
                    
                    if phone_both_count > 0:
                        print(f"\n    ğŸ” [ìƒ˜í”Œ - phone ë°ì´í„° ì¤‘ firstAskedAt ì—†ì§€ë§Œ createdAt ìˆëŠ” í–‰]")
                        phone_sample = phone_df[phone_both].head(3)
                        for idx, row in phone_sample.iterrows():
                            print(f"\n      í–‰ {idx}:")
                            print(f"        userId: {row.get('userId', 'N/A')}")
                            print(f"        direction: {row.get('direction', 'N/A')}")
                            print(f"        firstAskedAt: {row.get('firstAskedAt')}")
                            print(f"        createdAt: {row.get('createdAt')}")
                            
                            # OBê°€ ë§ëŠ”ì§€ í™•ì¸
                            if row.get('direction') != 'OB':
                                print(f"        âš ï¸ ê²½ê³ : directionì´ OBê°€ ì•„ë‹™ë‹ˆë‹¤! (í˜„ì¬: {row.get('direction')})")
                            else:
                                print(f"        âœ… directionì´ OBë¡œ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë¨")
        
        # ë©”íƒ€ë°ì´í„° í™•ì¸
        if meta_path and os.path.exists(meta_path):
            print(f"\nğŸ“„ ë©”íƒ€ë°ì´í„°:")
            with open(meta_path, 'r', encoding='utf-8') as f:
                meta = json.load(f)
            print(f"    ì €ì¥ì¼ì‹œ: {meta.get('saved_at', 'N/A')}")
            print(f"    ë°ì´í„° ê°œìˆ˜: {meta.get('data_count', 'N/A')}")
            print(f"    ì›”: {meta.get('month', 'N/A')}")
            if 'first_asked_start' in meta:
                print(f"    firstAskedAt ì‹œì‘: {meta.get('first_asked_start', 'N/A')}")
                print(f"    firstAskedAt ì¢…ë£Œ: {meta.get('first_asked_end', 'N/A')}")
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if name == "Docker" and meta_path.startswith("/tmp"):
                try:
                    os.unlink(meta_path)
                except:
                    pass
        
        print()
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        print()
